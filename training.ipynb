{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6850a2e-0b91-46f1-8b9e-96d5c317e4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./eug_env/lib/python3.11/site-packages (23.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b166f298-5e96-483c-9cbf-a06e63af9c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./eug_env/lib/python3.11/site-packages (4.33.1)\n",
      "Requirement already satisfied: filelock in ./eug_env/lib/python3.11/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in ./eug_env/lib/python3.11/site-packages (from transformers) (0.17.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./eug_env/lib/python3.11/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./eug_env/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./eug_env/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./eug_env/lib/python3.11/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in ./eug_env/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./eug_env/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./eug_env/lib/python3.11/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./eug_env/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in ./eug_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./eug_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./eug_env/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./eug_env/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./eug_env/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./eug_env/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: bitsandbytes in ./eug_env/lib/python3.11/site-packages (0.41.1)\n",
      "Requirement already satisfied: datasets in ./eug_env/lib/python3.11/site-packages (2.14.5)\n",
      "Requirement already satisfied: numpy>=1.17 in ./eug_env/lib/python3.11/site-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./eug_env/lib/python3.11/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in ./eug_env/lib/python3.11/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in ./eug_env/lib/python3.11/site-packages (from datasets) (2.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./eug_env/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./eug_env/lib/python3.11/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in ./eug_env/lib/python3.11/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in ./eug_env/lib/python3.11/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in ./eug_env/lib/python3.11/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in ./eug_env/lib/python3.11/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in ./eug_env/lib/python3.11/site-packages (from datasets) (0.17.1)\n",
      "Requirement already satisfied: packaging in ./eug_env/lib/python3.11/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./eug_env/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./eug_env/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./eug_env/lib/python3.11/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./eug_env/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./eug_env/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./eug_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./eug_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./eug_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in ./eug_env/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./eug_env/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./eug_env/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./eug_env/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./eug_env/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./eug_env/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./eug_env/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./eug_env/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in ./eug_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: torch in ./eug_env/lib/python3.11/site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in ./eug_env/lib/python3.11/site-packages (0.15.2)\n",
      "Requirement already satisfied: torchaudio in ./eug_env/lib/python3.11/site-packages (2.0.2)\n",
      "Requirement already satisfied: filelock in ./eug_env/lib/python3.11/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in ./eug_env/lib/python3.11/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in ./eug_env/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./eug_env/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./eug_env/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./eug_env/lib/python3.11/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./eug_env/lib/python3.11/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./eug_env/lib/python3.11/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./eug_env/lib/python3.11/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./eug_env/lib/python3.11/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./eug_env/lib/python3.11/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./eug_env/lib/python3.11/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./eug_env/lib/python3.11/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./eug_env/lib/python3.11/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./eug_env/lib/python3.11/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./eug_env/lib/python3.11/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./eug_env/lib/python3.11/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in ./eug_env/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.0)\n",
      "Requirement already satisfied: wheel in ./eug_env/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.41.2)\n",
      "Requirement already satisfied: cmake in ./eug_env/lib/python3.11/site-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
      "Requirement already satisfied: lit in ./eug_env/lib/python3.11/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: numpy in ./eug_env/lib/python3.11/site-packages (from torchvision) (1.25.2)\n",
      "Requirement already satisfied: requests in ./eug_env/lib/python3.11/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./eug_env/lib/python3.11/site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./eug_env/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./eug_env/lib/python3.11/site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./eug_env/lib/python3.11/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./eug_env/lib/python3.11/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./eug_env/lib/python3.11/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./eug_env/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy in ./eug_env/lib/python3.11/site-packages (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in ./eug_env/lib/python3.11/site-packages (from scipy) (1.25.2)\n",
      "Requirement already satisfied: accelerate in ./eug_env/lib/python3.11/site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./eug_env/lib/python3.11/site-packages (from accelerate) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./eug_env/lib/python3.11/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in ./eug_env/lib/python3.11/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in ./eug_env/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./eug_env/lib/python3.11/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: filelock in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: sympy in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./eug_env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: setuptools in ./eug_env/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (65.5.0)\n",
      "Requirement already satisfied: wheel in ./eug_env/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.41.2)\n",
      "Requirement already satisfied: cmake in ./eug_env/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.4.1)\n",
      "Requirement already satisfied: lit in ./eug_env/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./eug_env/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./eug_env/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install bitsandbytes\n",
    "!pip install datasets\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install scipy\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "588f1854-eb7d-4523-ad1c-f4c89c7e41f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Sep 14 18:02:04 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   53C    P8    31W / 350W |      1MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a593cc-2d0d-4427-84c7-86052d0d9c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.cuda.amp import custom_fwd, custom_bwd\n",
    "\n",
    "from bitsandbytes.functional import quantize_blockwise, dequantize_blockwise\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da8454c0-9462-4e6b-a2b6-5df5411583e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrozenBNBLinear(nn.Module):\n",
    "    def __init__(self, weight, absmax, code, bias=None):\n",
    "        assert isinstance(bias, nn.Parameter) or bias is None\n",
    "        super().__init__()\n",
    "        self.out_features, self.in_features = weight.shape\n",
    "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
    "        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n",
    "        self.register_buffer(\"code\", code.requires_grad_(False))\n",
    "        self.adapter = None\n",
    "        self.bias = bias\n",
    " \n",
    "    def forward(self, input):\n",
    "        output = DequantizeAndLinear.apply(input, self.weight, self.absmax, self.code, self.bias)\n",
    "        if self.adapter:\n",
    "            output += self.adapter(input)\n",
    "        return output\n",
    " \n",
    "    @classmethod\n",
    "    def from_linear(cls, linear: nn.Linear) -> \"FrozenBNBLinear\":\n",
    "        weights_int8, state = quantize_blockise_lowmemory(linear.weight)\n",
    "        return cls(weights_int8, *state, linear.bias)\n",
    " \n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}({self.in_features}, {self.out_features})\"\n",
    " \n",
    " \n",
    "class DequantizeAndLinear(torch.autograd.Function): \n",
    "    @staticmethod\n",
    "    @custom_fwd\n",
    "    def forward(ctx, input: torch.Tensor, weights_quantized: torch.ByteTensor,\n",
    "                absmax: torch.FloatTensor, code: torch.FloatTensor, bias: torch.FloatTensor):\n",
    "        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n",
    "        ctx.save_for_backward(input, weights_quantized, absmax, code)\n",
    "        ctx._has_bias = bias is not None\n",
    "        return F.linear(input, weights_deq, bias).clone()\n",
    " \n",
    "    @staticmethod\n",
    "    @custom_bwd\n",
    "    def backward(ctx, grad_output: torch.Tensor):\n",
    "        assert not ctx.needs_input_grad[1] and not ctx.needs_input_grad[2] and not ctx.needs_input_grad[3]\n",
    "        input, weights_quantized, absmax, code = ctx.saved_tensors\n",
    "        # grad_output: [*batch, out_features]\n",
    "        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n",
    "        grad_input = grad_output @ weights_deq\n",
    "        grad_bias = grad_output.flatten(0, -2).sum(dim=0) if ctx._has_bias else None\n",
    "        return grad_input, None, None, None, grad_bias\n",
    " \n",
    " \n",
    "class FrozenBNBEmbedding(nn.Module):\n",
    "    def __init__(self, weight, absmax, code):\n",
    "        super().__init__()\n",
    "        self.num_embeddings, self.embedding_dim = weight.shape\n",
    "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
    "        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n",
    "        self.register_buffer(\"code\", code.requires_grad_(False))\n",
    "        self.adapter = None\n",
    " \n",
    "    def forward(self, input, **kwargs):\n",
    "        with torch.no_grad():\n",
    "            # note: both quantuized weights and input indices are *not* differentiable\n",
    "            weight_deq = dequantize_blockwise(self.weight, absmax=self.absmax, code=self.code)\n",
    "            output = F.embedding(input, weight_deq, **kwargs)\n",
    "        if self.adapter:\n",
    "            output += self.adapter(input)\n",
    "        return output \n",
    " \n",
    "    @classmethod\n",
    "    def from_embedding(cls, embedding: nn.Embedding) -> \"FrozenBNBEmbedding\":\n",
    "        weights_int8, state = quantize_blockise_lowmemory(embedding.weight)\n",
    "        return cls(weights_int8, *state)\n",
    " \n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}({self.num_embeddings}, {self.embedding_dim})\"\n",
    " \n",
    " \n",
    "def quantize_blockise_lowmemory(matrix: torch.Tensor, chunk_size: int = 2 ** 20):\n",
    "    assert chunk_size % 4096 == 0\n",
    "    code = None\n",
    "    chunks = []\n",
    "    absmaxes = []\n",
    "    flat_tensor = matrix.view(-1)\n",
    "    for i in range((matrix.numel() - 1) // chunk_size + 1):\n",
    "        input_chunk = flat_tensor[i * chunk_size: (i + 1) * chunk_size].clone()\n",
    "        quantized_chunk, (absmax_chunk, code) = quantize_blockwise(input_chunk, code=code)\n",
    "        chunks.append(quantized_chunk)\n",
    "        absmaxes.append(absmax_chunk)\n",
    " \n",
    "    matrix_i8 = torch.cat(chunks).reshape_as(matrix)\n",
    "    absmax = torch.cat(absmaxes)\n",
    "    return matrix_i8, (absmax, code)\n",
    " \n",
    " \n",
    "def convert_to_int8(model):\n",
    "    \"\"\"Convert linear and embedding modules to 8-bit with optional adapters\"\"\"\n",
    "    for module in list(model.modules()):\n",
    "        for name, child in module.named_children():\n",
    "            if isinstance(child, nn.Linear):\n",
    "                print(name, child)\n",
    "                setattr( \n",
    "                    module,\n",
    "                    name,\n",
    "                    FrozenBNBLinear(\n",
    "                        weight=torch.zeros(child.out_features, child.in_features, dtype=torch.uint8),\n",
    "                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n",
    "                        code=torch.zeros(256),\n",
    "                        bias=child.bias,\n",
    "                    ),\n",
    "                )\n",
    "            elif isinstance(child, nn.Embedding):\n",
    "                setattr(\n",
    "                    module,\n",
    "                    name,\n",
    "                    FrozenBNBEmbedding(\n",
    "                        weight=torch.zeros(child.num_embeddings, child.embedding_dim, dtype=torch.uint8),\n",
    "                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n",
    "                        code=torch.zeros(256),\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6abd49ca-ad37-47bb-88de-2ec82df3726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTJBlock(transformers.models.gptj.modeling_gptj.GPTJBlock):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        convert_to_int8(self.attn)\n",
    "        convert_to_int8(self.mlp)\n",
    "\n",
    "\n",
    "class GPTJModel(transformers.models.gptj.modeling_gptj.GPTJModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        convert_to_int8(self)\n",
    "        \n",
    "\n",
    "class GPTJForCausalLM(transformers.models.gptj.modeling_gptj.GPTJForCausalLM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        convert_to_int8(self)\n",
    "\n",
    "\n",
    "transformers.models.gptj.modeling_gptj.GPTJBlock = GPTJBlock  # monkey-patch GPT-J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0db8ebf-7443-4762-b126-ff7f8362269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = transformers.GPTJConfig.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "436c20e0-c069-412d-885a-0e5b270d6dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "lm_head Linear(in_features=4096, out_features=50400, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTJForCausalLM(\n",
       "  (transformer): GPTJModel(\n",
       "    (wte): FrozenBNBEmbedding(50400, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-27): 28 x GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): FrozenBNBLinear(4096, 50400)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTJForCausalLM.from_pretrained(\"hivemind/gpt-j-6B-8bit\", low_cpu_mem_usage=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51031c90-29ae-41d7-9d85-2737d5ad85ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 s, sys: 0 ns, total: 11.2 s\n",
      "Wall time: 11.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'что на романе не оценили достаточный шанс расценки самого главного героя. «Серьезно, конечно, оценивают, но надеется, '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prompt = tokenizer(\"что\", return_tensors='pt')\n",
    "prompt = {key: value.to(device) for key, value in prompt.items()}\n",
    "out = gpt.generate(**prompt, min_length=128, max_length=128, do_sample=True)\n",
    "tokenizer.decode(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a6ee6ba-3cc2-42eb-858f-ae7691f6eec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34fa4478-3e4f-40ad-a7d4-eb61121df8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTJForCausalLM(\n",
       "  (transformer): GPTJModel(\n",
       "    (wte): FrozenBNBEmbedding(50400, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-27): 28 x GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): FrozenBNBLinear(4096, 50400)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_adapters(model, adapter_dim=16):\n",
    "    assert adapter_dim > 0\n",
    "\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, FrozenBNBLinear):\n",
    "            module.adapter = nn.Sequential(\n",
    "                nn.Linear(module.in_features, adapter_dim, bias=False),\n",
    "                nn.Linear(adapter_dim, module.out_features, bias=False),\n",
    "            )\n",
    "            nn.init.zeros_(module.adapter[1].weight)\n",
    "        elif isinstance(module, FrozenBNBEmbedding):\n",
    "            module.adapter = nn.Sequential(\n",
    "                nn.Embedding(module.num_embeddings, adapter_dim),\n",
    "                nn.Linear(adapter_dim, module.embedding_dim, bias=False),\n",
    "            )\n",
    "            nn.init.zeros_(module.adapter[1].weight)\n",
    "\n",
    "add_adapters(gpt)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "779e70c0-3c1b-433b-9735-bd1bb02330be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1472a6ecb5be47ff95a37d52635f00e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4952ca29dfb45558286baf5e5de0377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3769, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m batch \u001b[38;5;241m=\u001b[39m tokenizer(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m], truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mcuda() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 17\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mgpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(out\u001b[38;5;241m.\u001b[39mlogits[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m][:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[1;32m     20\u001b[0m                        reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[0;32m~/eug_env/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py:855\u001b[0m, in \u001b[0;36mGPTJForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    853\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 855\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/eug_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/eug_env/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py:690\u001b[0m, in \u001b[0;36mGPTJModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    681\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    682\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    683\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    687\u001b[0m         head_mask[i],\n\u001b[1;32m    688\u001b[0m     )\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 690\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/eug_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/eug_env/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py:309\u001b[0m, in \u001b[0;36mGPTJBlock.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, position_ids, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    307\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    308\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 309\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/eug_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/eug_env/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py:233\u001b[0m, in \u001b[0;36mGPTJAttention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, position_ids, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    230\u001b[0m q_rot \u001b[38;5;241m=\u001b[39m query[:, :, :, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_dim]\n\u001b[1;32m    231\u001b[0m q_pass \u001b[38;5;241m=\u001b[39m query[:, :, :, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_dim :]\n\u001b[0;32m--> 233\u001b[0m k_rot \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk_rot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m q_rot \u001b[38;5;241m=\u001b[39m apply_rotary_pos_emb(q_rot, sin, cos)\n\u001b[1;32m    236\u001b[0m key \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([k_rot, k_pass], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/eug_env/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py:78\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(tensor, sin, cos)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_rotary_pos_emb\u001b[39m(tensor: torch\u001b[38;5;241m.\u001b[39mTensor, sin: torch\u001b[38;5;241m.\u001b[39mTensor, cos: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     77\u001b[0m     sin \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrepeat_interleave(sin[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, :], \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m     cos \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcos\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (tensor \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_every_two(tensor) \u001b[38;5;241m*\u001b[39m sin)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from bitsandbytes.optim import Adam8bit\n",
    "\n",
    "gpt.gradient_checkpointing_enable()\n",
    "\n",
    "codeparrot = load_dataset(\"transformersbook/codeparrot-train\", streaming=True)\n",
    "optimizer = Adam8bit(gpt.parameters(), lr=1e-5)\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    for row in tqdm(codeparrot[\"train\"]):\n",
    "        if len(row[\"content\"]) <= 1:\n",
    "            continue\n",
    "\n",
    "        batch = tokenizer(row[\"content\"], truncation=True, max_length=128, return_tensors='pt')\n",
    "        batch = {k: v.cuda() for k, v in batch.items()}\n",
    "\n",
    "        out = gpt.forward(**batch,)\n",
    "\n",
    "        loss = F.cross_entropy(out.logits[:, :-1, :].flatten(0, -2), batch['input_ids'][:, 1:].flatten(),\n",
    "                               reduction='mean')\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
